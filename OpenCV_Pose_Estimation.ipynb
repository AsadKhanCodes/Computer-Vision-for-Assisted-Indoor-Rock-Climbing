{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.10.7)\n",
      "Requirement already satisfied: opencv-python in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: absl-py in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from mediapipe) (2.0.0)\n",
      "Requirement already satisfied: attrs>=19.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from mediapipe) (23.1.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from mediapipe) (23.5.26)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from mediapipe) (3.8.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from mediapipe) (1.26.1)\n",
      "Requirement already satisfied: opencv-contrib-python in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from mediapipe) (4.8.1.78)\n",
      "Requirement already satisfied: protobuf<4,>=3.11 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from mediapipe) (3.20.3)\n",
      "Requirement already satisfied: sounddevice>=0.4.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from mediapipe) (0.4.6)\n",
      "Requirement already satisfied: CFFI>=1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sounddevice>=0.4.4->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->mediapipe) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->mediapipe) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->mediapipe) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/lauramaldonado/Library/Python/3.10/lib/python/site-packages (from matplotlib->mediapipe) (23.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->mediapipe) (10.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib->mediapipe) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/lauramaldonado/Library/Python/3.10/lib/python/site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pycparser in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n",
      "Requirement already satisfied: six>=1.5 in /Users/lauramaldonado/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ultralytics in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (8.0.203)\n",
      "Requirement already satisfied: supervision in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.16.0)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ultralytics) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ultralytics) (1.26.1)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ultralytics) (4.8.1.78)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ultralytics) (10.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: requests>=2.23.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ultralytics) (1.11.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ultralytics) (2.1.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ultralytics) (0.16.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ultralytics) (2.1.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ultralytics) (0.13.0)\n",
      "Requirement already satisfied: psutil in /Users/lauramaldonado/Library/Python/3.10/lib/python/site-packages (from ultralytics) (5.9.6)\n",
      "Requirement already satisfied: py-cpuinfo in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.8.0.74 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from supervision) (4.8.1.78)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.43.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/lauramaldonado/Library/Python/3.10/lib/python/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/lauramaldonado/Library/Python/3.10/lib/python/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2023.10.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/lauramaldonado/Library/Python/3.10/lib/python/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mediapipe opencv-python\n",
    "%pip install ultralytics supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import supervision as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import uuid\n",
    "# import os\n",
    "# mp_hands = mp.solutions.hands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determining Joints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/3j8BPdc.png\" style=\"height:300px\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoseLandmark.NOSE\n",
      "PoseLandmark.LEFT_EYE_INNER\n",
      "PoseLandmark.LEFT_EYE\n",
      "PoseLandmark.LEFT_EYE_OUTER\n",
      "PoseLandmark.RIGHT_EYE_INNER\n",
      "PoseLandmark.RIGHT_EYE\n",
      "PoseLandmark.RIGHT_EYE_OUTER\n",
      "PoseLandmark.LEFT_EAR\n",
      "PoseLandmark.RIGHT_EAR\n",
      "PoseLandmark.MOUTH_LEFT\n",
      "PoseLandmark.MOUTH_RIGHT\n",
      "PoseLandmark.LEFT_SHOULDER\n",
      "PoseLandmark.RIGHT_SHOULDER\n",
      "PoseLandmark.LEFT_ELBOW\n",
      "PoseLandmark.RIGHT_ELBOW\n",
      "PoseLandmark.LEFT_WRIST\n",
      "PoseLandmark.RIGHT_WRIST\n",
      "PoseLandmark.LEFT_PINKY\n",
      "PoseLandmark.RIGHT_PINKY\n",
      "PoseLandmark.LEFT_INDEX\n",
      "PoseLandmark.RIGHT_INDEX\n",
      "PoseLandmark.LEFT_THUMB\n",
      "PoseLandmark.RIGHT_THUMB\n",
      "PoseLandmark.LEFT_HIP\n",
      "PoseLandmark.RIGHT_HIP\n",
      "PoseLandmark.LEFT_KNEE\n",
      "PoseLandmark.RIGHT_KNEE\n",
      "PoseLandmark.LEFT_ANKLE\n",
      "PoseLandmark.RIGHT_ANKLE\n",
      "PoseLandmark.LEFT_HEEL\n",
      "PoseLandmark.RIGHT_HEEL\n",
      "PoseLandmark.LEFT_FOOT_INDEX\n",
      "PoseLandmark.RIGHT_FOOT_INDEX\n"
     ]
    }
   ],
   "source": [
    "for lndmrk in mp_pose.PoseLandmark:\n",
    "    print(lndmrk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/qpRACer.png\" style=\"height:300px\" >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for ldmrk in mp_hands.HandLandmark:\n",
    "#     print(ldmrk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a = np.array(a) # First\n",
    "    b = np.array(b) # Mid\n",
    "    c = np.array(c) # End\n",
    "    \n",
    "    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])\n",
    "    angle = np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle >180.0:\n",
    "        angle = 360-angle\n",
    "        \n",
    "    return angle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_hand(image, hand_pts):\n",
    "    # DISPLAY AREA OF RIGHT HAND ---------------\n",
    "    # Calculate the center of the circle in 3D space (x, y, z)\n",
    "    center_3d = np.mean(hand_pts, axis=0)\n",
    "    # Calculate the radius of the circle in 3D space based on the average distance from the center to each point\n",
    "    distances = [np.linalg.norm([p[0] - center_3d[0], p[1] - center_3d[1], p[2] - center_3d[2]]) for p in hand_pts]\n",
    "\n",
    "    scaling_factor = 3  # scaling factor must be int\n",
    "    radius_3d = scaling_factor * int(sum(distances ) / len(distances))\n",
    "\n",
    "    # Draw the circle in 3D space\n",
    "    cv2.circle(image, (int(center_3d[0]), int(center_3d[1])), radius_3d, (245, 117, 66), thickness=-1)  # -1 thickness for a filled circle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feet_pts(ankle, heel, index, frame_shape_1, frame_shape_0):\n",
    "    return np.array([\n",
    "        [int(ankle.x * frame_shape_1), int(ankle.y * frame_shape_0)],\n",
    "        [int(heel.x * frame_shape_1), int(heel.y * frame_shape_0)],\n",
    "        [int(index.x * frame_shape_1), int(index.y * frame_shape_0)]\n",
    "        ], np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_pts(pinky, index, thumb, wrist, frame_shape_1, frame_shape_0):\n",
    "    return np.array([\n",
    "        [int(pinky.x * frame_shape_1), int(pinky.y * frame_shape_0)],\n",
    "        [int(index.x * frame_shape_1), int(index.y * frame_shape_0)],\n",
    "        [int(thumb.x * frame_shape_1), int(thumb.y * frame_shape_0)],\n",
    "        [int(wrist.x * frame_shape_1), int(wrist.y * frame_shape_0)]\n",
    "        ], np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_coords(d):\n",
    "    max_key_length = max(len(key) for key in d.keys())\n",
    "    max_x_length = max(len(str(value.x)) for value in d.values())\n",
    "    max_y_length = max(len(str(value.y)) for value in d.values())\n",
    "    max_z_length = max(len(str(value.z)) for value in d.values())\n",
    "\n",
    "    for point, coords in d.items():\n",
    "        formatted_x = str(coords.x).rjust(max_x_length)\n",
    "        formatted_y = str(coords.y).rjust(max_y_length)\n",
    "        formatted_z = str(coords.z).rjust(max_z_length)\n",
    "        print(f\"{point.ljust(max_key_length)}: x = {formatted_x}, y = {formatted_y}, z = {formatted_z}\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_within_hold(limb, detection):\n",
    "    x, y = limb.x, limb.y\n",
    "    x1, y1, x2, y2 = detection[0], detection[1], detection[2], detection[3]\n",
    "    # Check if limb coordinates are within the bounding box\n",
    "    return x1 <= x <= x2 and y1 <= y <= y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_center_point(d, limb, right_foot_pts, left_foot_pts, right_hand_pts, left_hand_pts):\n",
    "    r_foot = [\"right_ankle\", \"right_heel\", \"right_foot_index\"]\n",
    "    l_foot = [\"left_ankle\", \"left_heel\", \"left_foot_index\"]\n",
    "    r_hand = [\"right_pinky\", \"right_index\",\"right_thumb\", \"right_wrist\"]\n",
    "    l_hand = [\"left_pinky\", \"left_index\",\"left_thumb\", \"left_wrist\"]\n",
    "    if limb in r_foot:\n",
    "        return np.mean(right_foot_pts, axis=0)\n",
    "    elif limb in l_foot:\n",
    "        return np.mean(left_foot_pts, axis=0)\n",
    "    elif limb in r_hand:\n",
    "        return np.mean(right_hand_pts, axis=0)\n",
    "    elif limb in l_hand:\n",
    "        return np.mean(left_hand_pts, axis=0)\n",
    "    else:\n",
    "        return np.array([d[limb].x, d[limb].y], np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: function that checks what holds the person is on\n",
    "# A hold corresponding to right hand, left hand, right foot, left foot\n",
    "def get_curr_position(d, detections):\n",
    "    extremities = [\"right_foot\", \"left_foot\", \"right_hand\",\"left_hand\"]\n",
    "    for limb, coords in d.items():\n",
    "        for detection in detections:\n",
    "            # yields opposite corners\n",
    "            x1, y1, x2, y2 = detection[0], detection[1], detection[2], detection[3]\n",
    "            limb_x, limb_y = coords.x, coords.y\n",
    "\n",
    "            if (limb in extremities) and x1 <= limb_x <= x2 and y1 <= limb_y <= y2: # Within bounds\n",
    "                # save the coordinates\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relative_position(center_limb_pt, rock_hold):\n",
    "    # points of rock_hold\n",
    "    x1, y1, x2, y2 = rock_hold[0][0], rock_hold[0][1], rock_hold[0][2], rock_hold[0][3]\n",
    "    # print(\"Rock_coords:\", x1, y1, x2, y2)\n",
    "    mean_rock_coord = np.mean(np.array([[x1, y1], [x2, y2]]), axis=0)\n",
    "    # print(\"M:\", mean_rock_coord)\n",
    "    # print(\"C:\", center_limb_pt[:2])\n",
    "    return np.linalg.norm(abs(center_limb_pt[:2] - mean_rock_coord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative position: 562.5748712049328                      \r"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# JUST THE POSE\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "model = YOLO('bestHuge.pt')\n",
    "box_annotator = sv.BoxAnnotator(thickness=2, text_thickness=2, text_scale=1)\n",
    "detections = None\n",
    "\n",
    "## Setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.8, min_tracking_confidence=0.8) as pose:\n",
    "    seconds_passed = 0\n",
    "    start_time = time.time()\n",
    "    cv2.namedWindow('Calibration')\n",
    "    is_calibrating = True # Keeps track if you are at calibration phrase\n",
    "\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if is_calibrating:\n",
    "            print(f\"Calibrating... \" + \" \" * 20, end='\\r')\n",
    "            start_time = time.time()\n",
    "\n",
    "            while time.time() - start_time < 20:  # Change the time for calibration duration\n",
    "                ret, frame = cap.read()\n",
    "                cv2.putText(frame, \"Calibrating...\", (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (100, 0, 0), 2)\n",
    "                cv2.imshow('Pose Detection', frame)  # Update the window\n",
    "\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "            detections = sv.Detections.from_ultralytics(model(frame, verbose=False)[0])\n",
    "            detections = detections[detections.confidence > 0.8]\n",
    "            is_calibrating = False  # Set flag to end the calibration phase\n",
    "\n",
    "        else:\n",
    "\n",
    "            # Recolor image to RGB\n",
    "            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "\n",
    "            # Make detection\n",
    "            results = pose.process(image)\n",
    "\n",
    "            # annotate the scene with the detections\n",
    "            frame = box_annotator.annotate(scene=image, detections=detections)\n",
    "\n",
    "\n",
    "            # Recolor back to BGR\n",
    "            image.flags.writeable = True\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "\n",
    "            # Extract landmarks\n",
    "            try:\n",
    "                landmarks = results.pose_landmarks.landmark\n",
    "                pose_landmark = mp_pose.PoseLandmark\n",
    "\n",
    "                d = {}  # body dictionary\n",
    "\n",
    "                # Upper body coordinates\n",
    "                d[\"left_shoulder\"] = landmarks[pose_landmark.LEFT_SHOULDER.value]\n",
    "                d[\"right_shoulder\"] = landmarks[pose_landmark.RIGHT_SHOULDER]\n",
    "\n",
    "                d[\"left_elbow\"] = landmarks[pose_landmark.LEFT_ELBOW.value]\n",
    "                d[\"right_elbow\"] = landmarks[pose_landmark.RIGHT_ELBOW.value]\n",
    "\n",
    "                frame_shape_0, frame_shape_1 = frame.shape[0], frame.shape[1]\n",
    "\n",
    "                # LEFT HAND\n",
    "                d[\"left_pinky\"] = landmarks[pose_landmark.LEFT_PINKY.value]\n",
    "                d[\"left_index\"] = landmarks[pose_landmark.LEFT_INDEX.value]\n",
    "                d[\"left_thumb\"] = landmarks[pose_landmark.LEFT_THUMB.value]\n",
    "                d[\"left_wrist\"] = landmarks[pose_landmark.LEFT_WRIST.value]\n",
    "                left_hand_pts = hand_pts(d[\"left_pinky\"], d[\"left_index\"], d[\"left_thumb\"], d[\"left_wrist\"], frame_shape_1, frame_shape_0)\n",
    "\n",
    "                # RIGHT HAND\n",
    "                d[\"right_pinky\"] = landmarks[pose_landmark.RIGHT_PINKY.value]\n",
    "                d[\"right_index\"] = landmarks[pose_landmark.RIGHT_INDEX.value]\n",
    "                d[\"right_thumb\"] = landmarks[pose_landmark.RIGHT_THUMB.value]\n",
    "                d[\"right_wrist\"] = landmarks[pose_landmark.RIGHT_WRIST.value]\n",
    "                right_hand_pts = hand_pts(d[\"right_pinky\"], d[\"right_index\"], d[\"right_thumb\"], d[\"right_wrist\"], frame_shape_1, frame_shape_0)\n",
    "\n",
    "                # Lower body coordinates\n",
    "                d[\"left_knee\"] = landmarks[pose_landmark.LEFT_KNEE.value]\n",
    "                d[\"right_knee\"] = landmarks[pose_landmark.RIGHT_KNEE.value]\n",
    "\n",
    "                # LEFT FOOT\n",
    "                d[\"left_ankle\"] = landmarks[pose_landmark.LEFT_ANKLE.value]\n",
    "                d[\"left_heel\"] = landmarks[pose_landmark.LEFT_HEEL.value]\n",
    "                d[\"left_foot_index\"] = landmarks[pose_landmark.LEFT_FOOT_INDEX.value]\n",
    "                left_foot_pts = feet_pts(d[\"left_ankle\"], d[\"left_heel\"], d[\"left_foot_index\"], frame_shape_1, frame_shape_0)\n",
    "\n",
    "                # RIGHT FOOT\n",
    "                d[\"right_ankle\"] = landmarks[pose_landmark.RIGHT_ANKLE.value]\n",
    "                d[\"right_heel\"] = landmarks[pose_landmark.RIGHT_HEEL.value]\n",
    "                d[\"right_foot_index\"] = landmarks[pose_landmark.RIGHT_FOOT_INDEX.value]\n",
    "                right_foot_pts = feet_pts(d[\"right_ankle\"], d[\"right_heel\"], d[\"right_foot_index\"], frame_shape_1, frame_shape_0)\n",
    "\n",
    "                # Display Coordinates\n",
    "                # display_coords(d)\n",
    "\n",
    "                for detection in detections:\n",
    "                    # currently only for right_hand\n",
    "                    point = get_center_point(d, \"right_thumb\", right_foot_pts, left_foot_pts, right_hand_pts, left_hand_pts)\n",
    "                    get_relative_position(point, detection)\n",
    "                    print(f\"Relative position: {get_relative_position(point, detection)} \" + \" \" * 20, end='\\r')\n",
    "\n",
    "                # center_2d = np.mean(right_hand_pts, axis=0)[:2]\n",
    "\n",
    "                cv2.fillPoly(image, [right_foot_pts], (245, 117, 66))\n",
    "                cv2.fillPoly(image, [left_foot_pts], (245, 117, 66))\n",
    "\n",
    "                display_hand(image,right_hand_pts)\n",
    "                display_hand(image,left_hand_pts)\n",
    "\n",
    "                # Calculate angle\n",
    "                # angle = calculate_angle(shoulder, elbow, wrist)\n",
    "                # Visualize angle\n",
    "                # cv2.putText(image, str(angle),\n",
    "                #                tuple(np.multiply(elbow, [640, 480]).astype(int)),\n",
    "                #                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2, cv2.LINE_AA\n",
    "                #                     )\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            # print(results.pose_landmarks)\n",
    "            # Render detections\n",
    "            mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                    mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),\n",
    "                                    mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2))\n",
    "\n",
    "        cv2.imshow('Pose Detection', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
